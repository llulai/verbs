{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install beautifulsoup4\n",
    "#!pip install requests\n",
    "#!conda install pandas\n",
    "#!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return text.replace('/', '').strip().lower()\n",
    "\n",
    "\n",
    "def process_mode(row):\n",
    "    return clean_text(row.td.text)\n",
    "\n",
    "\n",
    "def process_times(row):\n",
    "    return tuple(clean_text(col.text) for col in row.find_all('td'))\n",
    "\n",
    "\n",
    "def process_conj(row, mode, times, infinitive):\n",
    "    verbs = []\n",
    "    cols = row.find_all('td')\n",
    "    \n",
    "    for i in range(0, 6, 2):\n",
    "        verbs.append(\n",
    "            dict(infinitive=infinitive,\n",
    "                 pess=cols[i].text,\n",
    "                 conj=cols[i + 1].text,\n",
    "                 time=times[i // 2],\n",
    "                 mode=mode\n",
    "                )\n",
    "        )\n",
    "        \n",
    "    return verbs\n",
    "\n",
    "\n",
    "\n",
    "def get_indicativo(infinitive:str, table:list) -> list:\n",
    "    \n",
    "    verbs = []\n",
    "    \n",
    "    for i, row in enumerate(table.find_all('tr')):\n",
    "        if i == 3:\n",
    "            mode = process_mode(row)\n",
    "        if i == 4 or i == 12:\n",
    "            times = process_times(row)\n",
    "        if 5 <= i <= 10 or 14 <= i <= 19:\n",
    "            verbs.extend(process_conj(row, mode, times, infinitive))\n",
    "    \n",
    "    return verbs\n",
    "\n",
    "def get_conjugations(verb):\n",
    "    r = requests.get(f\"http://www.conjuga-me.net/verbo-{verb}\")\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    indicativo = get_indicativo(verb, soup.find(class_=\"conj\"))\n",
    "    return indicativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ser'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_verb(verb):\n",
    "    return verb.replace('[', '').replace(']', '').lower().strip()\n",
    "\n",
    "#verbs = pd.read_clipboard().assign(verb=lambda df: df.verb.apply(clean_verb)).verb.values\n",
    "verbs = pd.read_csv('top_1000_verbs_pt.csv').verbs.values\n",
    "verbs[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_verbs = verbs[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:00<01:24,  1.16it/s]\u001b[A\n",
      "  2%|▏         | 2/100 [00:01<01:26,  1.14it/s]\u001b[A\n",
      "  3%|▎         | 3/100 [00:04<02:23,  1.48s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [00:05<02:04,  1.29s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [00:06<01:50,  1.17s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [00:07<01:42,  1.09s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [00:08<01:36,  1.04s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [00:09<01:41,  1.10s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [00:11<02:01,  1.34s/it]\u001b[A\n",
      " 10%|█         | 10/100 [00:12<01:46,  1.18s/it]\u001b[A\n",
      " 11%|█         | 11/100 [00:13<01:36,  1.09s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:14<01:33,  1.07s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:14<01:27,  1.00s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:15<01:21,  1.06it/s]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:16<01:16,  1.11it/s]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:17<01:16,  1.10it/s]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:18<01:14,  1.12it/s]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:19<01:18,  1.05it/s]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:21<01:36,  1.20s/it]\u001b[A\n",
      " 20%|██        | 20/100 [00:22<01:27,  1.09s/it]\u001b[A\n",
      " 21%|██        | 21/100 [00:22<01:19,  1.01s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:23<01:13,  1.06it/s]\u001b[A\n",
      " 23%|██▎       | 23/100 [00:24<01:15,  1.02it/s]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:25<01:11,  1.06it/s]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:26<01:07,  1.11it/s]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:27<01:05,  1.14it/s]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:28<01:04,  1.12it/s]\u001b[A\n",
      " 28%|██▊       | 28/100 [00:29<01:14,  1.04s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [00:30<01:09,  1.02it/s]\u001b[A\n",
      " 30%|███       | 30/100 [00:31<01:04,  1.08it/s]\u001b[A\n",
      " 31%|███       | 31/100 [00:31<01:02,  1.10it/s]\u001b[A\n",
      " 32%|███▏      | 32/100 [00:32<01:02,  1.09it/s]\u001b[A\n",
      " 33%|███▎      | 33/100 [00:33<01:01,  1.09it/s]\u001b[A\n",
      " 34%|███▍      | 34/100 [00:34<00:59,  1.11it/s]\u001b[A\n",
      " 35%|███▌      | 35/100 [00:35<00:56,  1.14it/s]\u001b[A\n",
      " 36%|███▌      | 36/100 [00:36<00:54,  1.17it/s]\u001b[A\n",
      " 37%|███▋      | 37/100 [00:37<00:53,  1.19it/s]\u001b[A\n",
      " 38%|███▊      | 38/100 [00:38<00:56,  1.10it/s]\u001b[A\n",
      " 39%|███▉      | 39/100 [00:39<00:56,  1.08it/s]\u001b[A\n",
      " 40%|████      | 40/100 [00:40<00:59,  1.02it/s]\u001b[A\n",
      " 41%|████      | 41/100 [00:41<00:58,  1.00it/s]\u001b[A\n",
      " 42%|████▏     | 42/100 [00:43<01:23,  1.44s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [00:44<01:16,  1.34s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [00:45<01:07,  1.20s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [00:46<01:01,  1.11s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [00:47<00:59,  1.11s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [00:48<00:55,  1.05s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [00:49<00:55,  1.07s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [00:50<00:52,  1.03s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [00:51<00:48,  1.03it/s]\u001b[A\n",
      " 51%|█████     | 51/100 [00:52<00:47,  1.02it/s]\u001b[A\n",
      " 52%|█████▏    | 52/100 [00:53<00:47,  1.01it/s]\u001b[A\n",
      " 53%|█████▎    | 53/100 [00:54<00:45,  1.03it/s]\u001b[A\n",
      " 54%|█████▍    | 54/100 [00:55<00:45,  1.01it/s]\u001b[A\n",
      " 55%|█████▌    | 55/100 [00:56<00:43,  1.03it/s]\u001b[A\n",
      " 56%|█████▌    | 56/100 [00:57<00:41,  1.05it/s]\u001b[A\n",
      " 57%|█████▋    | 57/100 [00:58<00:40,  1.06it/s]\u001b[A\n",
      " 58%|█████▊    | 58/100 [00:59<00:39,  1.07it/s]\u001b[A\n",
      " 59%|█████▉    | 59/100 [01:00<00:42,  1.03s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [01:01<00:39,  1.01it/s]\u001b[A\n",
      " 61%|██████    | 61/100 [01:02<00:36,  1.06it/s]\u001b[A\n",
      " 62%|██████▏   | 62/100 [01:03<00:34,  1.09it/s]\u001b[A\n",
      " 63%|██████▎   | 63/100 [01:03<00:32,  1.12it/s]\u001b[A\n",
      " 64%|██████▍   | 64/100 [01:04<00:32,  1.10it/s]\u001b[A\n",
      " 65%|██████▌   | 65/100 [01:05<00:32,  1.09it/s]\u001b[A\n",
      " 66%|██████▌   | 66/100 [01:06<00:31,  1.09it/s]\u001b[A\n",
      " 67%|██████▋   | 67/100 [01:07<00:30,  1.09it/s]\u001b[A\n",
      " 68%|██████▊   | 68/100 [01:08<00:29,  1.09it/s]\u001b[A\n",
      " 69%|██████▉   | 69/100 [01:09<00:27,  1.11it/s]\u001b[A\n",
      " 70%|███████   | 70/100 [01:10<00:29,  1.03it/s]\u001b[A\n",
      " 71%|███████   | 71/100 [01:11<00:26,  1.08it/s]\u001b[A\n",
      " 72%|███████▏  | 72/100 [01:12<00:25,  1.09it/s]\u001b[A\n",
      " 73%|███████▎  | 73/100 [01:13<00:23,  1.13it/s]\u001b[A\n",
      " 74%|███████▍  | 74/100 [01:13<00:22,  1.15it/s]\u001b[A\n",
      " 75%|███████▌  | 75/100 [01:14<00:21,  1.14it/s]\u001b[A\n",
      " 76%|███████▌  | 76/100 [01:15<00:21,  1.12it/s]\u001b[A\n",
      " 77%|███████▋  | 77/100 [01:16<00:19,  1.15it/s]\u001b[A\n",
      " 78%|███████▊  | 78/100 [01:17<00:19,  1.13it/s]\u001b[A\n",
      " 79%|███████▉  | 79/100 [01:18<00:18,  1.12it/s]\u001b[A\n",
      " 80%|████████  | 80/100 [01:19<00:18,  1.11it/s]\u001b[A\n",
      " 81%|████████  | 81/100 [01:20<00:18,  1.03it/s]\u001b[A\n",
      " 82%|████████▏ | 82/100 [01:21<00:16,  1.09it/s]\u001b[A\n",
      " 83%|████████▎ | 83/100 [01:22<00:15,  1.13it/s]\u001b[A\n",
      " 84%|████████▍ | 84/100 [01:22<00:13,  1.17it/s]\u001b[A\n",
      " 85%|████████▌ | 85/100 [01:23<00:12,  1.18it/s]\u001b[A\n",
      " 86%|████████▌ | 86/100 [01:24<00:12,  1.12it/s]\u001b[A\n",
      " 87%|████████▋ | 87/100 [01:25<00:11,  1.12it/s]\u001b[A\n",
      " 88%|████████▊ | 88/100 [01:26<00:10,  1.14it/s]\u001b[A\n",
      " 89%|████████▉ | 89/100 [01:27<00:09,  1.17it/s]\u001b[A\n",
      " 90%|█████████ | 90/100 [01:28<00:08,  1.14it/s]\u001b[A\n",
      " 91%|█████████ | 91/100 [01:29<00:08,  1.12it/s]\u001b[A\n",
      " 92%|█████████▏| 92/100 [01:29<00:07,  1.13it/s]\u001b[A\n",
      " 93%|█████████▎| 93/100 [01:30<00:06,  1.08it/s]\u001b[A\n",
      " 94%|█████████▍| 94/100 [01:31<00:05,  1.10it/s]\u001b[A\n",
      " 95%|█████████▌| 95/100 [01:32<00:04,  1.06it/s]\u001b[A\n",
      " 96%|█████████▌| 96/100 [01:33<00:03,  1.07it/s]\u001b[A\n",
      " 97%|█████████▋| 97/100 [01:34<00:02,  1.07it/s]\u001b[A\n",
      " 98%|█████████▊| 98/100 [01:35<00:01,  1.10it/s]\u001b[A\n",
      " 99%|█████████▉| 99/100 [01:36<00:00,  1.11it/s]\u001b[A\n",
      "100%|██████████| 100/100 [01:38<00:00,  1.17s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "parsed = []\n",
    "\n",
    "for verb in tqdm(verbs[:100]):\n",
    "    parsed.extend(get_conjugations(verb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(parsed).to_csv('top_100_pt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ser', 'ter', 'estar', 'poder', 'fazer', 'ir', 'haver', 'dizer',\n",
       "       'dar', 'ver', 'saber', 'querer', 'ficar', 'dever', 'passar', 'vir',\n",
       "       'chegar', 'falar', 'deixar', 'encontrar', 'levar', 'começar',\n",
       "       'partir', 'pensar', 'parecer', 'apresentar', 'olhar', 'tornar',\n",
       "       'sair', 'voltar', 'conseguir', 'achar', 'existir', 'sentir',\n",
       "       'entrar', 'chamar', 'conhecer', 'considerar', 'pôr', 'continuar',\n",
       "       'viver', 'ouvir', 'tomar', 'acabar', 'receber', 'perder', 'andar',\n",
       "       'trabalhar', 'criar', 'pedir', 'seguir', 'contar', 'acontecer',\n",
       "       'afirmar', 'tratar', 'esperar', 'gostar', 'usar', 'manter',\n",
       "       'realizar', 'abrir', 'escrever', 'permitir', 'ocorrer', 'mostrar',\n",
       "       'lembrar', 'trazer', 'procurar', 'morrer', 'tentar', 'formar',\n",
       "       'aparecer', 'incluir', 'cair', 'correr', 'ganhar', 'surgir',\n",
       "       'nascer', 'pagar', 'representar', 'entender', 'produzir', 'ler',\n",
       "       'precisar', 'perguntar', 'constituir', 'colocar', 'possuir',\n",
       "       'servir', 'tirar', 'responder', 'obter', 'desenvolver', 'explicar',\n",
       "       'descobrir', 'acreditar', 'levantar', 'mandar', 'estudar',\n",
       "       'atingir'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "decks = [\n",
    "    list(verbs[:10]),\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(verbs).rename(columns={0:'verbs'}).to_csv('top_1000_verbs_pt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verbs",
   "language": "python",
   "name": "verbs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
